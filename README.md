# CS2558-Project

The implementation of contextual multi-armed bandits using Thompson sampling that can adopt different prior distributions and hypothesized models to control regularization and interaction effects.

Report can be found at: https://hackmd.io/@haibara/ByA8wqE7w
